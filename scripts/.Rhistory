#https://rpubs.com/rosenblum_jeff/censustutorial1
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
library(acs)
library(stringr)
api.key.install(key="9925cc88cedfbda155532ef9c85d5a64888d85d3")
texas_counties = c("Harris", "Dallas", "Tarrant", "Bexar", "Travis", "Collin", "Denton", "Hidalgo", "El Paso", "Fort Bend", "Montgomery", "Williamson", "Cameron", "Brazoria", "Bell", "Galveston", "Nueces", "Lubbock", "Webb", "McLennan", "Hays", "Jefferson", "Smith", "Brazos", "Ellis", "Johnson", "Guadalupe", "Comal", "Midland", "Ector", "Kaufman", "Parker", "Randall", "Taylor", "Grayson", "Wichita", "Gregg", "Tom Green", "Potter", "Rockwall", "Hunt", "Bastrop", "Liberty", "Bowie", "Victoria", "Angelina", "Orange", "Coryell", "Henderson", "Walker", "Wise", "San Patricio", "Harrison", "Starr", "Nacogdoches", "Hood", "Van Zandt", "Waller", "Anderson", "Maverick", "Hardin", "Navarro", "Kerr", "Rusk", "Medina", "Polk", "Wilson", "Cherokee", "Burnet", "Lamar", "Atascosa", "Chambers", "Val Verde", "Caldwell", "Kendall", "Wood", "Erath", "Cooke", "Upshur", "Wharton", "Jim Wells", "Brown", "Hopkins", "Fannin", "Hill", "Matagorda", "Washington", "Howard", "Jasper", "Hale", "Titus", "Bee", "Kleberg", "Austin", "Grimes", "Palo Pinto", "Cass", "San Jacinto", "Gillespie", "Milam", "Uvalde", "Fayette", "Aransas", "Shelby", "Panola", "Lampasas", "Houston", "Limestone", "Llano", "Gaines", "Bandera", "Hockley", "Moore", "Gray", "Colorado", "Lavaca", "Hutchinson", "Montague", "Willacy", "Tyler", "DeWitt", "Jones", "Freestone", "Calhoun", "Gonzales", "Bosque", "Andrews", "Frio", "Deaf Smith", "Burleson", "Young", "Eastland", "Lee", "Falls", "Robertson", "Scurry", "Leon", "Jackson", "Pecos", "Karnes", "Nolan", "Reeves", "Callahan", "Zapata", "Trinity", "Comanche", "Madison", "Lamb", "Wilbarger", "Camp", "Rains", "Dawson", "Newton", "Morris", "Blanco", "Terry", "Red River", "Live Oak", "Ward", "Franklin", "Clay", "Sabine", "Runnels", "Parmer", "Ochiltree", "Duval", "Marion", "Zavala", "Somervell", "Brewster", "Stephens", "Mitchell", "Jack", "Archer", "Dimmit", "Hamilton", "San Augustine", "Coleman", "Yoakum", "McCulloch", "Winkler", "Castro", "Dallam", "Goliad", "Swisher", "Brooks", "Bailey", "Refugio", "Childress", "La Salle", "Presidio", "Garza", "San Saba", "Carson", "Lynn", "Haskell", "Hartley", "Delta", "Floyd", "Martin", "Hansford", "Crosby", "Wheeler", "Jim Hogg", "Crane", "Mills", "Kimble", "Mason", "Fisher", "Hardeman", "Baylor", "Knox", "Concho", "Coke", "Sutton", "Hudspeth", "Hemphill", "Donley", "Upton", "Reagan", "Shackelford", "Kinney", "Crockett", "Lipscomb", "Hall", "Real", "Sherman", "Collingsworth", "Cochran", "Schleicher", "Culberson", "Menard", "Jeff Davis", "Armstrong", "Dickens", "Oldham", "Irion", "Throckmorton", "Edwards", "Briscoe", "Sterling", "Cottle", "Stonewall", "Glasscock", "Foard", "Motley", "Roberts", "Kent", "Terrell", "Borden", "McMullen", "Kenedy", "King", "Loving")
### GET FIPS CODES
counties = data.frame()
for (i in texas_counties) {
fips = geo.lookup(state="TX", county=i)
#print(paste(fips[2,1],str_pad(fips[2,3], 3, pad="0"), collapse="", sep=""))
counties = rbind(
counties,
c(i,
paste(fips[2,1],str_pad(fips[2,3], 3, pad="0"), collapse="", sep=""),
fips[2,3]
)
)
}
colnames(counties) = c("County","fips", "County Code")
counties$fips = as.numeric(counties$fips)
counties$`County Code` = as.numeric(counties$`County Code`)
### GET PAPER DATA
papers = read_excel("../UNCNewspaperDatabase_12_17_20.xlsx")
thrc_data = read.csv("../thrc_data_v1_3.csv")
papers = read_excel("../2022TPADirectory_Jan2022.xlsx")
papers = read_excel("../2022TPADirectory_Jan2022.xlsx")
thrc_data = read_csv("../thrc_data_merged.csv")
View(thrc_data)
View(papers)
?merge
tmp = merge(papers, thrc_data, by.x = 'County', by.y = 'Name', all.x = TRUE)
View(tmp)
duplicated(tmp)
tmp[duplicated(tmp),]$Nam
tmp[duplicated(tmp),]$Name
tmp[duplicated(tmp),]
tmp = merge(papers, thrc_data, by.x = 'County', by.y = 'Name')
papers = merge(papers, thrc_data, by.x = 'County', by.y = 'Name')
write.csv('../TPA_Papers_THRC_merge.csv', row.names = FALSE)
write.csv(papers,'../TPA_Papers_THRC_merge.csv', row.names = FALSE)
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
papers = read_excel("../2022TPADirectory_Jan2022.xlsx")
thrc_data = read_csv("../thrc_data_merged.csv")
View(papers)
papers = merge(papers, thrc_data, by.x = 'County', by.y = 'Name')
View(papers)
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
papers = read_excel("../2022TPADirectory_Jan2022.xlsx")
thrc_data = read_csv("../thrc_data_merged.csv")
?merge
?inner_join
tmp = left_join(papers, thrc_data, by = c('County','Name'))
tmp = left_join(papers, thrc_data, by = c('County' = 'Name'))
View(tmp)
View(thrc_data)
load("~/Documents/Academics/News Deserts/data/scripts/20220908_added_median_income.RData")
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
library(acs)
library(stringr)
thrc_data = read.csv("../thrc_data_v1_3.csv")
thrc_data[duplicated(thrc_data),]
View(counties)
counties[duplicated(counties),]
#https://rpubs.com/rosenblum_jeff/censustutorial1
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
library(acs)
library(stringr)
texas_counties = c("Harris", "Dallas", "Tarrant", "Bexar", "Travis", "Collin", "Denton", "Hidalgo", "El Paso", "Fort Bend", "Montgomery", "Williamson", "Cameron", "Brazoria", "Bell", "Galveston", "Nueces", "Lubbock", "Webb", "McLennan", "Hays", "Jefferson", "Smith", "Brazos", "Ellis", "Johnson", "Guadalupe", "Comal", "Midland", "Ector", "Kaufman", "Parker", "Randall", "Taylor", "Grayson", "Wichita", "Gregg", "Tom Green", "Potter", "Rockwall", "Hunt", "Bastrop", "Liberty", "Bowie", "Victoria", "Angelina", "Orange", "Coryell", "Henderson", "Walker", "Wise", "San Patricio", "Harrison", "Starr", "Nacogdoches", "Hood", "Van Zandt", "Waller", "Anderson", "Maverick", "Hardin", "Navarro", "Kerr", "Rusk", "Medina", "Polk", "Wilson", "Cherokee", "Burnet", "Lamar", "Atascosa", "Chambers", "Val Verde", "Caldwell", "Kendall", "Wood", "Erath", "Cooke", "Upshur", "Wharton", "Jim Wells", "Brown", "Hopkins", "Fannin", "Hill", "Matagorda", "Washington", "Howard", "Jasper", "Hale", "Titus", "Bee", "Kleberg", "Austin", "Grimes", "Palo Pinto", "Cass", "San Jacinto", "Gillespie", "Milam", "Uvalde", "Fayette", "Aransas", "Shelby", "Panola", "Lampasas", "Houston", "Limestone", "Llano", "Gaines", "Bandera", "Hockley", "Moore", "Gray", "Colorado", "Lavaca", "Hutchinson", "Montague", "Willacy", "Tyler", "DeWitt", "Jones", "Freestone", "Calhoun", "Gonzales", "Bosque", "Andrews", "Frio", "Deaf Smith", "Burleson", "Young", "Eastland", "Lee", "Falls", "Robertson", "Scurry", "Leon", "Jackson", "Pecos", "Karnes", "Nolan", "Reeves", "Callahan", "Zapata", "Trinity", "Comanche", "Madison", "Lamb", "Wilbarger", "Camp", "Rains", "Dawson", "Newton", "Morris", "Blanco", "Terry", "Red River", "Live Oak", "Ward", "Franklin", "Clay", "Sabine", "Runnels", "Parmer", "Ochiltree", "Duval", "Marion", "Zavala", "Somervell", "Brewster", "Stephens", "Mitchell", "Jack", "Archer", "Dimmit", "Hamilton", "San Augustine", "Coleman", "Yoakum", "McCulloch", "Winkler", "Castro", "Dallam", "Goliad", "Swisher", "Brooks", "Bailey", "Refugio", "Childress", "La Salle", "Presidio", "Garza", "San Saba", "Carson", "Lynn", "Haskell", "Hartley", "Delta", "Floyd", "Martin", "Hansford", "Crosby", "Wheeler", "Jim Hogg", "Crane", "Mills", "Kimble", "Mason", "Fisher", "Hardeman", "Baylor", "Knox", "Concho", "Coke", "Sutton", "Hudspeth", "Hemphill", "Donley", "Upton", "Reagan", "Shackelford", "Kinney", "Crockett", "Lipscomb", "Hall", "Real", "Sherman", "Collingsworth", "Cochran", "Schleicher", "Culberson", "Menard", "Jeff Davis", "Armstrong", "Dickens", "Oldham", "Irion", "Throckmorton", "Edwards", "Briscoe", "Sterling", "Cottle", "Stonewall", "Glasscock", "Foard", "Motley", "Roberts", "Kent", "Terrell", "Borden", "McMullen", "Kenedy", "King", "Loving")
counties = data.frame()
for (i in texas_counties) {
fips = geo.lookup(state="TX", county=i)
#print(paste(fips[2,1],str_pad(fips[2,3], 3, pad="0"), collapse="", sep=""))
counties = rbind(
counties,
c(i,
paste(fips[2,1],str_pad(fips[2,3], 3, pad="0"), collapse="", sep=""),
fips[2,3]
)
)
}
colnames(counties) = c("County","fips", "County Code")
counties$fips = as.numeric(counties$fips)
counties$`County Code` = as.numeric(counties$`County Code`)
papers = read_excel("../UNCNewspaperDatabase_12_17_20.xlsx")
papers_tx = papers %>% filter(
state == "TX"
)
papers_counties = papers_tx %>% group_by(county) %>% summarise(
papers = n()
)
for (i in texas_counties[!(texas_counties %in% papers_counties$county)]) {
papers_counties = rbind(papers_counties, c(i,0))
}
papers_counties$desert = FALSE
papers_counties[papers_counties$papers <= 1,]$desert = TRUE
counties = merge(counties, papers_counties, by.x = 'County', by.y = 'county')
load("~/Documents/Academics/News Deserts/data/scripts/20220908_added_median_income.RData")
View(counties)
texas_counties = c("Harris", "Dallas", "Tarrant", "Bexar", "Travis", "Collin", "Denton", "Hidalgo", "El Paso", "Fort Bend", "Montgomery", "Williamson", "Cameron", "Brazoria", "Bell", "Galveston", "Nueces", "Lubbock", "Webb", "McLennan", "Hays", "Jefferson", "Smith", "Brazos", "Ellis", "Johnson", "Guadalupe", "Comal", "Midland", "Ector", "Kaufman", "Parker", "Randall", "Taylor", "Grayson", "Wichita", "Gregg", "Tom Green", "Potter", "Rockwall", "Hunt", "Bastrop", "Liberty", "Bowie", "Victoria", "Angelina", "Orange", "Coryell", "Henderson", "Walker", "Wise", "San Patricio", "Harrison", "Starr", "Nacogdoches", "Hood", "Van Zandt", "Waller", "Anderson", "Maverick", "Hardin", "Navarro", "Kerr", "Rusk", "Medina", "Polk", "Wilson", "Cherokee", "Burnet", "Lamar", "Atascosa", "Chambers", "Val Verde", "Caldwell", "Kendall", "Wood", "Erath", "Cooke", "Upshur", "Wharton", "Jim Wells", "Brown", "Hopkins", "Fannin", "Hill", "Matagorda", "Washington", "Howard", "Jasper", "Hale", "Titus", "Bee", "Kleberg", "Austin", "Grimes", "Palo Pinto", "Cass", "San Jacinto", "Gillespie", "Milam", "Uvalde", "Fayette", "Aransas", "Shelby", "Panola", "Lampasas", "Houston", "Limestone", "Llano", "Gaines", "Bandera", "Hockley", "Moore", "Gray", "Colorado", "Lavaca", "Hutchinson", "Montague", "Willacy", "Tyler", "DeWitt", "Jones", "Freestone", "Calhoun", "Gonzales", "Bosque", "Andrews", "Frio", "Deaf Smith", "Burleson", "Young", "Eastland", "Lee", "Falls", "Robertson", "Scurry", "Leon", "Jackson", "Pecos", "Karnes", "Nolan", "Reeves", "Callahan", "Zapata", "Trinity", "Comanche", "Madison", "Lamb", "Wilbarger", "Camp", "Rains", "Dawson", "Newton", "Morris", "Blanco", "Terry", "Red River", "Live Oak", "Ward", "Franklin", "Clay", "Sabine", "Runnels", "Parmer", "Ochiltree", "Duval", "Marion", "Zavala", "Somervell", "Brewster", "Stephens", "Mitchell", "Jack", "Archer", "Dimmit", "Hamilton", "San Augustine", "Coleman", "Yoakum", "McCulloch", "Winkler", "Castro", "Dallam", "Goliad", "Swisher", "Brooks", "Bailey", "Refugio", "Childress", "La Salle", "Presidio", "Garza", "San Saba", "Carson", "Lynn", "Haskell", "Hartley", "Delta", "Floyd", "Martin", "Hansford", "Crosby", "Wheeler", "Jim Hogg", "Crane", "Mills", "Kimble", "Mason", "Fisher", "Hardeman", "Baylor", "Knox", "Concho", "Coke", "Sutton", "Hudspeth", "Hemphill", "Donley", "Upton", "Reagan", "Shackelford", "Kinney", "Crockett", "Lipscomb", "Hall", "Real", "Sherman", "Collingsworth", "Cochran", "Schleicher", "Culberson", "Menard", "Jeff Davis", "Armstrong", "Dickens", "Oldham", "Irion", "Throckmorton", "Edwards", "Briscoe", "Sterling", "Cottle", "Stonewall", "Glasscock", "Foard", "Motley", "Roberts", "Kent", "Terrell", "Borden", "McMullen", "Kenedy", "King", "Loving")
### GET FIPS CODES
counties = data.frame()
for (i in texas_counties) {
fips = geo.lookup(state="TX", county=i)
#print(paste(fips[2,1],str_pad(fips[2,3], 3, pad="0"), collapse="", sep=""))
counties = rbind(
counties,
c(i,
paste(fips[2,1],str_pad(fips[2,3], 3, pad="0"), collapse="", sep=""),
fips[2,3]
)
)
}
colnames(counties) = c("County","fips", "County Code")
counties$fips = as.numeric(counties$fips)
counties$`County Code` = as.numeric(counties$`County Code`)
### GET PAPER DATA
papers = read_excel("../UNCNewspaperDatabase_12_17_20.xlsx")
papers_tx = papers %>% filter(
state == "TX"
)
papers_counties = papers_tx %>% group_by(county) %>% summarise(
papers = n()
)
for (i in texas_counties[!(texas_counties %in% papers_counties$county)]) {
papers_counties = rbind(papers_counties, c(i,0))
}
papers_counties$desert = FALSE
papers_counties[papers_counties$papers <= 1,]$desert = TRUE
counties = merge(counties, papers_counties, by.x = 'County', by.y = 'county')
## MERGE WITH NEWSPAPER DATA
counties$`County Code` = str_pad(counties$`County Code`,3,pad = '0')
tmp = merge(counties,acs_county_data,by.x='County Code', by.y='County Code')
counties$`County Code` !%in% acs_county_data$`County Code`
counties$`County Code` %in% acs_county_data$`County Code`
tmp = inner_join(counties, acs_county_data)
View(tmp)
tmp = left_join(counties, acs_county_data)
tmp = right_join(counties, acs_county_data)
tmp[duplicated(tmp),]
View(tmp)
View(counties)
#https://rpubs.com/rosenblum_jeff/censustutorial1
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
library(acs)
library(stringr)
api.key.install(key="9925cc88cedfbda155532ef9c85d5a64888d85d3")
### GET FIPS CODES from THRC data
thrc_data = read.csv("../thrc_data_v1_3.csv")
counties = thrc_data[,c(1,2)]
papers = read_excel("../UNCNewspaperDatabase_12_17_20.xlsx")
papers_tx = papers %>% filter(
state == "TX"
)
papers_counties = papers_tx %>% group_by(county) %>% summarise(
papers = n()
)
for (i in texas_counties[!(texas_counties %in% papers_counties$county)]) {
papers_counties = rbind(papers_counties, c(i,0))
}
counties = merge(counties, papers_counties, by.x = 'Name', by.y = 'county')
#https://rpubs.com/rosenblum_jeff/censustutorial1
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
library(acs)
library(stringr)
api.key.install(key="9925cc88cedfbda155532ef9c85d5a64888d85d3")
### GET FIPS CODES from THRC data
thrc_data = read.csv("../thrc_data_v1_3.csv")
counties = thrc_data[,c(1,2)]
papers = read_excel("../UNCNewspaperDatabase_12_17_20.xlsx")
papers_tx = papers %>% filter(
state == "TX"
)
papers_counties = papers_tx %>% group_by(county) %>% summarise(
papers = n()
)
texas_counties = counties$Name
for (i in texas_counties[!(texas_counties %in% papers_counties$county)]) {
papers_counties = rbind(papers_counties, c(i,0))
}
papers_counties$desert = FALSE
papers_counties[papers_counties$papers <= 1,]$desert = TRUE
counties = merge(counties, papers_counties, by.x = 'Name', by.y = 'county')
View(counties)
## SETUP ACS VARIABLES THAT WE WANT
acs.tables.install()
span = 5
endyear = 2020
geo_counties = geo.make(state=48, county=counties$`County Code`)
geo_counties = geo.make(state=48, county=str_sub(counties$fips,start = -3))
str_sub(counties$fips,start = -3)
geo_counties = geo.make(state=48, county=as.numeric(str_sub(counties$fips,start = -3)))
table_hispanic = acs.lookup(endyear = endyear, table.number="B03002")
#results(mytable)$variable.name
var_hispanic_total = table_hispanic[1]
var_hispanic = table_hispanic[12]
table_poverty = acs.lookup(endyear = endyear, table.number="B17001")
var_poverty_total = table_poverty[1]
var_poverty = table_poverty[2]
table_gini = acs.lookup(endyear = endyear, table.number="B19083")
var_gini = table_gini[1]
table_education = acs.lookup(endyear = endyear, table.number="B15003")
var_education_total = table_education[1]
var_highschool = table_education[17]
var_ged = table_education[18]
var_bachelors = table_education[22]
var_masters = table_education[23]
var_professional_degree = table_education[24]
var_doctorate = table_education[25]
table_snap = acs.lookup(endyear = endyear, table.number="B22001")
var_snap_total = table_snap[1]
var_snap = table_snap[2]
table_employment = acs.lookup(endyear = endyear, table.number="B23025")
var_employment_total = table_employment[3]
var_unemployed = table_employment[5]
table_income = acs.lookup(endyear = endyear, table.number="B19013")
var_median_household_income = table_income[1]
acs_variables = c(
var_hispanic_total,
var_hispanic,
var_poverty_total,
var_poverty,
var_gini,
var_education_total,
var_highschool,
var_ged,
var_bachelors,
var_masters,
var_professional_degree,
var_doctorate,
var_snap_total,
var_snap,
var_employment_total,
var_unemployed,
var_median_household_income
)
## GET THE ACS DATA
acs_data = acs.fetch(
endyear=endyear,
span=span,
geography=geo_counties,
variable=acs_variables
)
tmp_hispanic_percent = acs_data@estimate[,2] / acs_data@estimate[,1]
tmp_poverty_percent = acs_data@estimate[,4] / acs_data@estimate[,3]
tmp_highschool_percent = acs_data@estimate[,7] / acs_data@estimate[,6]
tmp_ged_percent = acs_data@estimate[,8] / acs_data@estimate[,6]
tmp_bachelors_percent = acs_data@estimate[,9] / acs_data@estimate[,6]
tmp_masters_percent = acs_data@estimate[,10] / acs_data@estimate[,6]
tmp_professional_percent = acs_data@estimate[,11] / acs_data@estimate[,6]
tmp_doctorate_percent = acs_data@estimate[,12] / acs_data@estimate[,6]
tmp_snap_percent = acs_data@estimate[,14] / acs_data@estimate[,13]
tmp_unemployment_percent = acs_data@estimate[,16] / acs_data@estimate[,15]
acs_county_data = data.frame(
acs_data@geography$county,
tmp_hispanic_percent, # Hispanic percent
tmp_poverty_percent, # Poverty percent
acs_data@estimate[,5], # GINI index
tmp_highschool_percent, # Highschool percent
tmp_ged_percent, # ged percent
tmp_bachelors_percent, # bachelors percent
tmp_masters_percent, # masters percent
tmp_professional_percent, # professional percent
tmp_doctorate_percent, # doctorate percent
tmp_snap_percent, # snap percent
tmp_unemployment_percent, # unemployment percent
acs_data@estimate[,17] # median household income
)
colnames(acs_county_data) = c(
'County Code',
'ACS5Y2020_Hispanic_Percent',
'ACS5Y2020_Poverty_Percent',
'ACS5Y2020_GINI_Index',
'ACS5Y2020_Highschool_Percent',
'ACS5Y2020_GED_Percent',
'ACS5Y2020_Bachelors_Percent',
'ACS5Y2020_Masters_Percent',
'ACS5Y2020_Professional_Percent',
'ACS5Y2020_Doctorate_Percent',
'ACS5Y2020_SNAP_Percent',
'ACS5Y2020_Unemployment_Percent',
'Median Household Income'
)
colnames(acs_county_data) = c(
'County Code',
'ACS5Y2020_Hispanic_Percent',
'ACS5Y2020_Poverty_Percent',
'ACS5Y2020_GINI_Index',
'ACS5Y2020_Highschool_Percent',
'ACS5Y2020_GED_Percent',
'ACS5Y2020_Bachelors_Percent',
'ACS5Y2020_Masters_Percent',
'ACS5Y2020_Professional_Percent',
'ACS5Y2020_Doctorate_Percent',
'ACS5Y2020_SNAP_Percent',
'ACS5Y2020_Unemployment_Percent',
'ACS5Y2020_Median Household Income'
)
View(acs_county_data)
save.image("~/Documents/Academics/News Deserts/data/scripts/20220908_added_median_income.RData")
## MERGE WITH NEWSPAPER DATA
counties$`County Code` = str_pad(counties$`County Code`,3,pad = '0')
## MERGE WITH NEWSPAPER DATA
counties$`County Code` = str_pad(counties$fips,3,pad = '0')
## MERGE WITH NEWSPAPER DATA
counties$`County Code` = str_sub(counties$fips,start = -3)
counties = merge(counties,acs_county_data,by.x='County Code', by.y='County Code')
View(counties)
date()
format(today, format="%Y%m%d")
format(date(), format="%Y%m%d")
Sys.Date()
format(Sys.Date(), format="%Y%m%d")
write.csv(acs_county_data, file=paste("../", format(Sys.Date(), format="%Y%m%d"), "acs_data.csv", sep="", collapse=""))
write.csv(acs_county_data, file=paste("../", "acs_data_", format(Sys.Date(), format="%Y%m%d"), ".csv", sep="", collapse=""))
counties$`County Code` = str_sub(counties$fips,start = -3)
counties = merge(counties,acs_county_data,by.x='County Code', by.y='County Code')
View(counties)
counties = subset(counties, select = -c(County,`County Code`) )
names(counties)[names(counties) == 'papers'] <- 'UNC2020_Count_Papers'
counties$Zero_Papers = FALSE
counties$One_Or_Fewer_Papers = FALSE
counties[counties$UNC2020_Count_Papers == 0,]$Zero_Papers = TRUE
counties[counties$UNC2020_Count_Papers <= 1,]$One_Or_Fewer_Papers = TRUE
tmp = merge(thrc_data, counties, by = 'fips')
View(tmp)
duplicated(tmp)
write.csv(thrc_data, file=paste("../", "thrc_data_merged_", format(Sys.Date(), format="%Y%m%d"), ".csv", sep="", collapse=""))
write.csv(thrc_data, file=paste("../", "thrc_data_merged_latest.csv", sep="", collapse=""))
write.csv(thrc_data, file=paste("../", "thrc_data_merged_", format(Sys.Date(), format="%Y%m%d"), ".csv", sep="", collapse=""))
write.csv(thrc_data, file=paste("../", "thrc_data_merged_latest.csv", sep="", collapse=""))
write.csv(acs_county_data, file=paste("../", "acs_data_latest.csv", sep="", collapse=""))
thrc_data = read_csv("../thrc_data_merged_latest.csv")
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
papers = read_excel("../2022TPADirectory_Jan2022.xlsx")
thrc_data = read_csv("../thrc_data_merged_latest.csv")
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
papers = read_excel("../2022TPADirectory_Jan2022.xlsx")
thrc_data = read_csv("../thrc_data_merged_latest.csv")
tmp = left_join(papers, thrc_data, by = c('County' = 'Name'))
View(tmp)
View(thrc_data)
load("~/Documents/Academics/News Deserts/data/scripts/20220908_added_median_income.RData")
View(acs_county_data)
write.csv(acs_county_data, file=paste("../", "acs_data_", format(Sys.Date(), format="%Y%m%d"), ".csv", sep="", collapse=""), row.names = FALSE)
write.csv(acs_county_data, file=paste("../", "acs_data_latest.csv", sep="", collapse=""), row.names = FALSE)
write.csv(thrc_data, file=paste("../", "thrc_data_merged_", format(Sys.Date(), format="%Y%m%d"), ".csv", sep="", collapse=""), row.names = FALSE)
write.csv(thrc_data, file=paste("../", "thrc_data_merged_latest.csv", sep="", collapse=""), row.names = FALSE)
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
papers = read_excel("../2022TPADirectory_Jan2022.xlsx")
thrc_data = read_csv("../thrc_data_merged_latest.csv")
papers = left_join(papers, thrc_data, by = c('County' = 'Name'))
View(papers)
write.csv(papers, file=paste("../", "tpa_thrc_merged_", format(Sys.Date(), format="%Y%m%d"), ".csv", sep="", collapse=""), row.names = FALSE)
write.csv(papers, file=paste("../", "tpa_thrc_merged_latest.csv", sep="", collapse=""), row.names = FALSE)
View(thrc_data)
load("~/Documents/Academics/News Deserts/data/scripts/20220908_added_median_income.RData")
counties$`County Code` = str_sub(counties$fips,start = -3)
counties = merge(counties,acs_county_data,by.x='County Code', by.y='County Code')
names(counties)[names(counties) == 'papers'] <- 'UNC2020_Count_Papers'
counties$Zero_Papers = FALSE
counties$One_Or_Fewer_Papers = FALSE
counties[counties$UNC2020_Count_Papers == 0,]$Zero_Papers = TRUE
counties[counties$UNC2020_Count_Papers <= 1,]$One_Or_Fewer_Papers = TRUE
# MERGE WITH THRC DATA
thrc_data = merge(thrc_data, counties, by = 'fips')
write.csv(thrc_data, file=paste("../", "thrc_data_merged_", format(Sys.Date(), format="%Y%m%d"), ".csv", sep="", collapse=""), row.names = FALSE)
write.csv(thrc_data, file=paste("../", "thrc_data_merged_latest.csv", sep="", collapse=""), row.names = FALSE)
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
papers = read_excel("../2022TPADirectory_Jan2022.xlsx")
thrc_data = read_csv("../thrc_data_merged_latest.csv")
papers = left_join(papers, thrc_data, by = c('County' = 'Name'))
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
papers = read_excel("../2022TPADirectory_Jan2022.xlsx")
thrc_data = read_csv("../thrc_data_merged_latest.csv")
View(thrc_data)
load("~/Documents/Academics/News Deserts/data/scripts/20220908_added_median_income.RData")
## MERGE WITH NEWSPAPER DATA
counties$`County Code` = str_sub(counties$fips,start = -3)
counties = merge(counties,acs_county_data,by.x='County Code', by.y='County Code')
names(counties)[names(counties) == 'papers'] <- 'UNC2020_Count_Papers'
counties$Zero_Papers = FALSE
counties$One_Or_Fewer_Papers = FALSE
counties[counties$UNC2020_Count_Papers == 0,]$Zero_Papers = TRUE
counties[counties$UNC2020_Count_Papers <= 1,]$One_Or_Fewer_Papers = TRUE
thrc_data = merge(thrc_data, counties, by = 'fips')
names(thrc_data)[names(thrc_data) == 'Name.x'] <- 'Name'
write.csv(thrc_data, file=paste("../", "thrc_data_merged_", format(Sys.Date(), format="%Y%m%d"), ".csv", sep="", collapse=""), row.names = FALSE)
write.csv(thrc_data, file=paste("../", "thrc_data_merged_latest.csv", sep="", collapse=""), row.names = FALSE)
save.image("~/Documents/Academics/News Deserts/data/scripts/20220908_added_median_income.RData")
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
papers = read_excel("../2022TPADirectory_Jan2022.xlsx")
thrc_data = read_csv("../thrc_data_merged_latest.csv")
papers = left_join(papers, thrc_data, by = c('County' = 'Name'))
write.csv(papers, file=paste("../", "tpa_thrc_merged_", format(Sys.Date(), format="%Y%m%d"), ".csv", sep="", collapse=""), row.names = FALSE)
write.csv(papers, file=paste("../", "tpa_thrc_merged_latest.csv", sep="", collapse=""), row.names = FALSE)
papers[is.na(papers$One_Or_Fewer_Papers),]
load("~/Documents/Academics/News Deserts/data/scripts/20220908_added_median_income.RData")
setwd("~/Documents/Academics/News Deserts/data/scripts")
library(tidyverse)
library(readxl)
papers = read_excel("../2022TPADirectory_Jan2022.xlsx")
thrc_data = read_csv("../thrc_data_merged_latest.csv")
thrc_data[is.na(thrc_data$One_Or_Fewer_Papers),]
View(papers)
View(thrc_data)
thrc_data[thrc_data$Name == "Hale",]$One_Or_Fewer_Papers
tmp = left_join(papers, thrc_data, by = c('County' = 'Name'))
View(tmp)
tmp = merge(papers, thrc_data, by.x = 'County', by.y = 'Name', all.x = TRUE)
View(tmp)
papers[papers$County == "Hale"]
papers[papers$County == "Hale",]
papers[is.na(papers$County),]
papers$County = trimws(papers$County)
papers[papers$County == "Hale",]
thrc_data = read_csv("../thrc_data_merged_latest.csv")
tmp = left_join(papers, thrc_data, by = c('County' = 'Name'))
View(tmp)
write.csv(papers, file=paste("../", "tpa_thrc_merged_", format(Sys.Date(), format="%Y%m%d"), ".csv", sep="", collapse=""), row.names = FALSE)
write.csv(papers, file=paste("../", "tpa_thrc_merged_latest.csv", sep="", collapse=""), row.names = FALSE)
papers = left_join(papers, thrc_data, by = c('County' = 'Name'))
write.csv(papers, file=paste("../", "tpa_thrc_merged_", format(Sys.Date(), format="%Y%m%d"), ".csv", sep="", collapse=""), row.names = FALSE)
write.csv(papers, file=paste("../", "tpa_thrc_merged_latest.csv", sep="", collapse=""), row.names = FALSE)
